<!DOCTYPE html>
<html>

<head>
	<script src="face-api.js"></script>
	<script src="js/drawing.js"></script>
	<script src="js/faceDetectionControls.js"></script>
	<link rel="stylesheet" href="styles.css">
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/css/materialize.css">
	<script type="text/javascript" src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/js/materialize.min.js"></script>
	<script src="https://raw.githubusercontent.com/eligrey/FileSaver.js/master/dist/FileSaver.js"></script>
</head>

<body>
	<div class="center-content page-container">

		<div class="progress" id="loader">
			<div class="indeterminate"></div>
		</div>
		<div style="position: relative" class="margin">
			<video src="bbt.mp4" id="inputVideo" autoplay muted loop controls></video>
			<canvas id="overlay" />
		</div>
		<div class="showImage"></div>
</body>

<script>
	let forwardTimes = []
	let withFaceLandmarks = false
	let withBoxes = true

	function onChangeWithFaceLandmarks(e) {
		withFaceLandmarks = $(e.target).prop('checked')
	}

	function onChangeHideBoundingBoxes(e) {
		withBoxes = !$(e.target).prop('checked')
	}

	function updateTimeStats(timeInMs) {
		forwardTimes = [timeInMs].concat(forwardTimes).slice(0, 30)
		const avgTimeInMs = forwardTimes.reduce((total, t) => total + t) / forwardTimes.length
		$('#time').val(`${Math.round(avgTimeInMs)} ms`)
		$('#fps').val(`${faceapi.round(1000 / avgTimeInMs)}`)
	}

	async function onPlay(videoEl) {
		if (!videoEl.currentTime || videoEl.paused || videoEl.ended || !isFaceDetectionModelLoaded())
			return setTimeout(() => onPlay(videoEl))

		const options = getFaceDetectorOptions()

		const ts = Date.now()

		const faceDetectionTask = faceapi.detectAllFaces(videoEl, options)

		const results = withFaceLandmarks
			? await faceDetectionTask.withFaceLandmarks()
			: await faceDetectionTask

		updateTimeStats(Date.now() - ts)

		const drawFunction = withFaceLandmarks
			? drawLandmarks
			: drawDetections

		drawFunction(videoEl, $('#overlay').get(0), results, withBoxes)

		if (faceDetectionTask && faceDetectionTask.input && faceDetectionTask.options) {
			var canvaslength = $("#my-canvas").length;
			if (canvaslength === 0 && results.length > 0 && results[0].score >= 0.80) {
				$('div.showImage').append(captureAsCanvas(videoEl, { width: 200, height: 200 }));
				saveAsImage();
			}
		}

		setTimeout(() => onPlay(videoEl))
	}

	function saveAsImage() {
		var canvas = document.getElementById('my-canvas');
		var dataURL = canvas.toDataURL('image/png');
		$('div.showImage').append('<img src=' + dataURL + ' alt="Red dot"></img>');
	}

	function captureAsCanvas(video, size) {
		var canvas = $('<canvas id="my-canvas" />').attr({ width: size.width, height: size.height })[0];
		canvas.getContext('2d').drawImage(video, 0, 0, size.width, size.height)
		return canvas;
	}

	async function run() {
		await changeFaceDetector(TINY_FACE_DETECTOR)
		await faceapi.loadFaceLandmarkModel('/')
		changeInputSize(416)

		onPlay($('#inputVideo').get(0))
	}

	function updateResults() { }

	$(document).ready(function () {
		initFaceDetectionControls()
		run()
	})
</script>
</body>

</html>